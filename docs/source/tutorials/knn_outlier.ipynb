{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f65acd",
   "metadata": {},
   "source": [
    "# Detecting Outliers with Cleanlab's outlier detection algorithm\n",
    "\n",
    "This 5-minute quickstart tutorial shows how to detect potential outliers in image classification data. The dataset used is `cifar10` which contains 60,000 images. Each image belongs to 1 of 10 categories: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. \n",
    "\n",
    "**Overview of what we'll do in this tutorial:**\n",
    "\n",
    "- Load the [`cifar10`](https://www.cs.toronto.edu/~kriz/cifar.html) dataset and do some basic data pre-processing.\n",
    "- Create `trainX` and `testX` such that `testX` contains extra categories\n",
    "- Load pretrained model and extract feature embeddings of `trainX` and `testX`\n",
    "- Compute outlier scores for each example using cleanlab's `get_outlier_scores` method and analyze results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e987fa",
   "metadata": {},
   "source": [
    "## 1. Install the required dependencies\n",
    "You can use `pip` to install all packages required for this tutorial as follows:\n",
    "\n",
    "```ipython3\n",
    "!pip install torch\n",
    "!pip install cleanlab\n",
    "...\n",
    "# Make sure to install the version corresponding to this tutorial\n",
    "# E.g. if viewing master branch documentation:\n",
    "#     !pip install git+https://github.com/cleanlab/cleanlab.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b552a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package installation (hidden on docs website).\n",
    "# If running on Colab, may want to use GPU (select: Runtime > Change runtime type > Hardware accelerator > GPU)\n",
    "\n",
    "dependencies = [\"cleanlab\", \"matplotlib\", \"torch\", \"pylab\", \"keras\", \"sklearn\", \"timm\", ]\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):  # Check if it's running in Google Colab\n",
    "    %pip install cleanlab  # for colab\n",
    "    cmd = ' '.join([dep for dep in dependencies if dep != \"cleanlab\"])\n",
    "    %pip install $cmd\n",
    "else:\n",
    "    missing_dependencies = []\n",
    "    for dependency in dependencies:\n",
    "        try:\n",
    "            __import__(dependency)\n",
    "        except ImportError:\n",
    "            missing_dependencies.append(dependency)\n",
    "\n",
    "    if len(missing_dependencies) > 0:\n",
    "        print(\"Missing required dependencies:\")\n",
    "        print(*missing_dependencies, sep=\", \")\n",
    "        print(\"\\nPlease install them before running the rest of this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e76f30",
   "metadata": {},
   "source": [
    "Lets first set some seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4de93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "# SEED = 123\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "warnings.filterwarnings(\"ignore\", \"Lazy modules are a new feature.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d0618",
   "metadata": {},
   "source": [
    "## 2. Fetch and scale the Cifar10 dataset\n",
    "\n",
    "After some basic preprocessing, we manually remove some categories from the training data, making them outliers in the test set. For this example we've chosen to remove all categories that are not an animal `[airplane, automobile, ship, truck]` from the training set `trainX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "from keras.datasets import cifar10, cifar100\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae35d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cifar10 datasets\n",
    "(trainX, trainy), (testX, testy) = cifar10.load_data()\n",
    "trainX, _, trainy, _ = train_test_split(trainX, trainy, test_size=0.5, stratify=trainy, random_state=SEED) # only use 50% of each label\n",
    "\n",
    "# Convert from integers to floats and normalize range 0-1\n",
    "trainX = trainX.astype('float32') / 255.0\n",
    "testX = testX.astype('float32') / 255.0\n",
    "\n",
    "# Manually remove non-animals out of the training dataset\n",
    "animal_labels = [2,3,4,5,6,7]\n",
    "animal_idxs = np.where(np.isin(trainy, animal_labels))[0] # find idx of animals\n",
    "trainX = trainX[animal_idxs]\n",
    "trainy = trainy[animal_idxs]\n",
    "\n",
    "# Check the shapes of our training and test sets\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4480c85",
   "metadata": {},
   "source": [
    "#### Lets visualize some of the training and test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a7bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_labels = {0: 'airplane', \n",
    "              1: 'automobile', \n",
    "              2: 'bird',\n",
    "              3: 'cat', \n",
    "              4: 'deer', \n",
    "              5: 'dog', \n",
    "              6: 'frog', \n",
    "              7: 'horse', \n",
    "              8:'ship', \n",
    "              9:'truck'}\n",
    "\n",
    "def plot_images(X,y):\n",
    "    plt.rcParams[\"figure.figsize\"] = (9,7)\n",
    "    for i in range(15):\n",
    "        # define subplot\n",
    "        ax = plt.subplot(3,5,i+1)\n",
    "        ax.set_title(txt_labels[int(y[i])])\n",
    "        # plot raw pixel data\n",
    "        ax.imshow(X[i])\n",
    "    # show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd30c983",
   "metadata": {},
   "source": [
    "Observe how there are only animals left in the training set `trainX` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486acf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(trainX,trainy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf11eb8",
   "metadata": {},
   "source": [
    "The test set on the other hand still visibily contains the non-animal images: ship, airplane, automobile, truck. If we consider `trainX` to be the representation of data, then these non-animal images in `testX` become outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2fdd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(testX,testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f57bae",
   "metadata": {},
   "source": [
    "## 3. Import a model and embeddings\n",
    "The model we are importing comes from `timm`, a deep-learning library collection of SOTA models and utilities.\n",
    "\n",
    "The model itself is a `resnet50` but outlier detection can be done with any object capable of generating feature embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd151d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import timm\n",
    "\n",
    "model = timm.create_model('resnet50', pretrained=True, num_classes=0) # download the model from timm\n",
    "trainX_torch = torch.from_numpy(trainX.swapaxes(1,3)) # turn trainX into tensor and fix channel dimension\n",
    "train_feature_embeddings = model(trainX_torch) # fit model to train images and get train embeddings\n",
    "train_feature_embeddings = train_feature_embeddings.detach().numpy() # change type to numpy array\n",
    "print(f'Pooled shape: {train_feature_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802dece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = timm.create_model('resnet50', pretrained=True, num_classes=0) # download the model from timm\n",
    "testX_torch = torch.from_numpy(testX.swapaxes(1,3)) # turn trainX into tensor and fix channel dimension\n",
    "test_feature_embeddings = model(testX_torch) # fit model to train images and get train embeddings\n",
    "test_feature_embeddings = test_feature_embeddings.detach().numpy() # change type to numpy array\n",
    "print(f'Pooled shape: {test_feature_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83792c57",
   "metadata": {},
   "source": [
    "## 4. Import cleanlab and find outliers in the dataset\n",
    "We can use the `cleanlab` library to try and find the artificially added outlier examples `[airplanes, automobiles, trucks, boats]` in the test dataset. We can also check the training data to find any naturally occuring outlier examples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aacc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleanlab\n",
    "from cleanlab.rank import get_outlier_scores\n",
    "from sklearn.neighbors import NearestNeighbors # import KNN estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49026d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KNN estimator and fit it on the resnet50 feature embeddings\n",
    "knn = NearestNeighbors(n_neighbors=10).fit(train_feature_embeddings)\n",
    "\n",
    "# get outlier scores for the test feature embeddings\n",
    "outlier_scores = get_outlier_scores(features=test_feature_embeddings, knn=knn, k=10)\n",
    "\n",
    "# visualize top 15 outlier scores\n",
    "top_outlier_idxs = (outlier_scores).argsort()[:15]\n",
    "plot_images(testX[top_outlier_idxs],testy[top_outlier_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25a681",
   "metadata": {},
   "source": [
    "Notice how majority of the outliers belong to the holdout classes (airplane, automobile, ship). These feature representations are futher away in the model representation space than the training dataset representations. \n",
    "\n",
    "Just for fun, lets visualize what the NearestNeighbors algorithm considers the 15 least probable outliers in our test set. Notice there are a lot less images from the out of distribution classes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fd623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize least probable 15 outlier scores\n",
    "bottom_outlier_idxs = (-outlier_scores).argsort()[:15]\n",
    "plot_images(testX[bottom_outlier_idxs],testy[bottom_outlier_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf08aa3",
   "metadata": {},
   "source": [
    "We can also compute the precision/recall of our algorithm for the examples. [Jonas is this important?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c9df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "animal_labels = [2,3,4,5,6,7] # identify animal labels in the testing dataset\n",
    "animal_idxs = np.where(np.isin(testy, animal_labels))[0] # find idx of animals\n",
    "not_outlier = np.zeros(len(testy), dtype=bool) # is outlier\n",
    "not_outlier[animal_idxs] = True\n",
    "precision, recall, thresholds = precision_recall_curve(not_outlier, 1 - outlier_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\", fontsize=14)\n",
    "plt.ylabel(\"Precision\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692f978",
   "metadata": {},
   "source": [
    "### Finding naturally occuring outlier examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76571ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outlier scores for our train feature embeddings\n",
    "outlier_scores = get_outlier_scores(features=train_feature_embeddings, k=10)\n",
    "\n",
    "# visualize top 15 outlier scores\n",
    "top_train_outlier_idxs = (outlier_scores).argsort()[:15]\n",
    "plot_images(trainX[top_train_outlier_idxs],trainy[top_train_outlier_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d203a",
   "metadata": {},
   "source": [
    "Just for fun, lets see what our model considers the least likeley outliers in the training set! These examples are very homogeneous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize bottom 12 outlier scores on train set\n",
    "top_outlier_idxs = (-outlier_scores).argsort()[:15]\n",
    "plot_images(trainX[top_outlier_idxs],trainy[top_outlier_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b830e",
   "metadata": {},
   "source": [
    "## 4. Discovering outliers during training [remove for tutorial, add to example notebook]\n",
    "What if our training data contained only a couple outliers? We can use Cleanlab to find these label issues!\n",
    "\n",
    "**Lets add a couple ship outliers from the test set into our training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2c2b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a couple ship outliers from testX to the training dataset\n",
    "num_outliers_to_add = 25\n",
    "\n",
    "# Manually remove non-animals out of the training dataset\n",
    "animal_labels = [2,3,4,5,6,7]\n",
    "outlier_labels = [1] # outlier labels = [0,1,8,9]\n",
    "outlier_idxs = np.where(np.isin(testy, outlier_labels))[0] # find idx of non-animals\n",
    "\n",
    "# Select and visualize several examples from test set\n",
    "testX_outliers = testX[outlier_idxs]\n",
    "testy_outliers = testy[outlier_idxs]\n",
    "plot_images(testX_outliers[:15],testy_outliers[:15])\n",
    "\n",
    "# Now lets randomly assign non-outlier labels to our outlier data\n",
    "testX_outliers = testX_outliers[:num_outliers_to_add]\n",
    "trainy_outliers = np.random.choice(animal_labels, num_outliers_to_add, replace=True)[:,np.newaxis]\n",
    "\n",
    "# Lets add the first x ships as outliers to the training data. You can change num_outliers_to_add to add more or less.\n",
    "trainX_outliers = np.concatenate([trainX,testX_outliers])\n",
    "trainy_outliers = np.concatenate([trainy,trainy_outliers])\n",
    "\n",
    "# Check the shapes of our new training set contains outliers and test sets\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Train with outliers: X=%s, y=%s' % (trainX_outliers.shape, trainy_outliers.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0ec4e5",
   "metadata": {},
   "source": [
    "**Just like last time, get embeddings from a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a63e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = timm.create_model('resnet50', pretrained=True, num_classes=0) # download the model from timm\n",
    "trainX_outliers_torch = torch.from_numpy(trainX_outliers.swapaxes(1,3)) # turn trainX into tensor and fix channel dimension\n",
    "outliers_feature_embeddings = model(trainX_outliers_torch) # fit model to train images and get train embeddings\n",
    "outliers_feature_embeddings = outliers_feature_embeddings.detach().numpy() # change type to numpy array\n",
    "print(f'Pooled shape: {outliers_feature_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3545b062",
   "metadata": {},
   "source": [
    "**Find naturally occuring examples and get outlier scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba40d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outlier scores for our train feature embeddings\n",
    "outlier_scores = get_outlier_scores(features=outliers_feature_embeddings, k=10)\n",
    "\n",
    "# visualize top 15 outlier scores\n",
    "top_outlier_idxs = (outlier_scores).argsort()[:100]\n",
    "true_labels = np.concatenate([trainy,testy_outliers]) # get real labels\n",
    "plot_images(trainX_outliers[top_outlier_idxs],true_labels[top_outlier_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08978fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_scores[top_outlier_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b64c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_scores[-25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c554498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This cell is only for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "top_outlier_idxs_test = [4102, 9193, 6549, 5146, 4294, 3281, 8698, 1802, 2254, 8886, 4734,408,  770, 2513, 2909]\n",
    "bottom_outlier_idxs_test = [6165, 5020, 8466, 1914, 4322, 5113, 6697, 7608,  273, 7802, 7795,4325,  910, 6125, 9815]\n",
    "top_outlier_idxs_train = [ 8083,   370,  8931,  5719,  8245,  2568, 12055,  9209,  3905,9630, 12033, 11411,  8624,  2162, 10587]\n",
    "\n",
    "if not all(x in top_outlier_idxs for x in top_outlier_idxs_test):\n",
    "    raise Exception(\"Some highlighted examples are missing from top outliers in test set.\")\n",
    "\n",
    "if not all(x in bottom_outlier_idxs for x in bottom_outlier_idxs_test):\n",
    "    raise Exception(\"Some highlighted examples are missing from bottom test set outliers.\")\n",
    "\n",
    "if not all(x in top_train_outlier_idxs for x in top_outlier_idxs_train):\n",
    "    raise Exception(\"Some highlighted examples are missing from finding naturally occuring outliers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d8beb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanlab-p38",
   "language": "python",
   "name": "cleanlab-p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
