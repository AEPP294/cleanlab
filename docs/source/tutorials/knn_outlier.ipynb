{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f65acd",
   "metadata": {},
   "source": [
    "# Detecting Outliers with Cleanlab and Sklearn\n",
    "\n",
    "This 5-minute quickstart tutorial shows how to detect potential outliers in image classification data. The dataset used is `cifar10` which contains 60,000 images. Each image belongs to 1 of 10 categories: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. \n",
    "\n",
    "**Overview of what we'll do in this tutorial:**\n",
    "\n",
    "- Load the [cifar10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset and do some basic data pre-processing.\n",
    "- Create `trainX` and `testX` such that `testX` contains extra categories\n",
    "- Load pretrained model and extract feature embeddings of `trainX` and `testX`\n",
    "- Compute outlier scores for each example using cleanlab's `get_outlier_scores` method and analyze results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e987fa",
   "metadata": {},
   "source": [
    "## 1. Install the required dependencies\n",
    "You can use `pip` to install all packages required for this tutorial as follows:\n",
    "\n",
    "```ipython3\n",
    "!pip install torch\n",
    "!pip install cleanlab\n",
    "...\n",
    "# Make sure to install the version corresponding to this tutorial\n",
    "# E.g. if viewing master branch documentation:\n",
    "#     !pip install git+https://github.com/cleanlab/cleanlab.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b552a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package installation (hidden on docs website).\n",
    "# If running on Colab, may want to use GPU (select: Runtime > Change runtime type > Hardware accelerator > GPU)\n",
    "\n",
    "dependencies = [\"cleanlab\", \"matplotlib\", \"torch\", \"pylab\", \"keras\", \"sklearn\", \"timm\", ]\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):  # Check if it's running in Google Colab\n",
    "    %pip install cleanlab  # for colab\n",
    "    cmd = ' '.join([dep for dep in dependencies if dep != \"cleanlab\"])\n",
    "    %pip install $cmd\n",
    "else:\n",
    "    missing_dependencies = []\n",
    "    for dependency in dependencies:\n",
    "        try:\n",
    "            __import__(dependency)\n",
    "        except ImportError:\n",
    "            missing_dependencies.append(dependency)\n",
    "\n",
    "    if len(missing_dependencies) > 0:\n",
    "        print(\"Missing required dependencies:\")\n",
    "        print(*missing_dependencies, sep=\", \")\n",
    "        print(\"\\nPlease install them before running the rest of this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e76f30",
   "metadata": {},
   "source": [
    "Lets first set some seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4de93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "warnings.filterwarnings(\"ignore\", \"Lazy modules are a new feature.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d0618",
   "metadata": {},
   "source": [
    "## 2. Fetch and scale the Cifar10 dataset\n",
    "\n",
    "Import `cifar10` dataset. After some basic preprocessing, we manually remove some categories from the training data thereby making them outliers in the test set. For this example we've chosen to remove all categories that are not an animal `[airplane, automobile, ship, truck]` from the training set `trainX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "from keras.datasets import cifar10, cifar100\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae35d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cifar10 datasets\n",
    "(trainX, trainy), (testX, testy) = cifar10.load_data()\n",
    "trainX, _, trainy, _ = train_test_split(trainX, trainy, test_size=0.5, stratify=trainy, random_state=SEED) # only use 50% of each label\n",
    "\n",
    "# Convert from integers to floats and normalize range 0-1\n",
    "trainX = trainX.astype('float32') / 255.0\n",
    "testX = testX.astype('float32') / 255.0\n",
    "\n",
    "# Manually remove non-animals out of the training dataset\n",
    "animal_labels = [2,3,4,5,6,7]\n",
    "animal_idxs = np.where(np.isin(trainy, animal_labels))[0] # find idx of animals\n",
    "trainX = trainX[animal_idxs]\n",
    "trainy = trainy[animal_idxs]\n",
    "\n",
    "# Check the shapes of our training and test sets\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4480c85",
   "metadata": {},
   "source": [
    "#### Lets visualize some of the training and test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a7bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_labels = {0: 'airplane', \n",
    "              1: 'automobile', \n",
    "              2: 'bird',\n",
    "              3: 'cat', \n",
    "              4: 'deer', \n",
    "              5: 'dog', \n",
    "              6: 'frog', \n",
    "              7: 'horse', \n",
    "              8:'ship', \n",
    "              9:'truck'}\n",
    "\n",
    "def plot_images(X,y):\n",
    "    plt.rcParams[\"figure.figsize\"] = (9,7)\n",
    "    for i in range(15):\n",
    "        # define subplot\n",
    "        ax = plt.subplot(3,5,i+1)\n",
    "        ax.set_title(txt_labels[int(y[i])])\n",
    "        # plot raw pixel data\n",
    "        ax.imshow(X[i])\n",
    "    # show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dddf313",
   "metadata": {},
   "source": [
    "Observe how there are only animals left in the training set `trainX` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486acf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(trainX,trainy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf11eb8",
   "metadata": {},
   "source": [
    "The test set on the other hand still visibily contains the non-animal images: `[ship, airplane, automobile, truck]`. If we consider `trainX` to be the representation of data, then these non-animal images in test dataset `testX` become outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2fdd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(testX,testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f57bae",
   "metadata": {},
   "source": [
    "## 3. Import a model and embeddings\n",
    "The model we are importing comes from [timm](https://timm.fast.ai/), a deep-learning library collection of SOTA models and utilities. We pass in the images into the model to generate embeddings in the feature space used in outlier detection.\n",
    "\n",
    "The model itself is a `resnet50` but outlier detection can be done with any object capable of generating feature embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd151d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import timm\n",
    "\n",
    "# This cell can take ~1-2 mins\n",
    "model = timm.create_model('resnet50', pretrained=True, num_classes=0) # download the model from timm\n",
    "trainX_torch = torch.from_numpy(trainX.swapaxes(1,3)) # turn trainX into tensor and fix channel dimension\n",
    "train_feature_embeddings = model(trainX_torch) # fit model to train images and get train feature embeddings\n",
    "train_feature_embeddings = train_feature_embeddings.detach().numpy() # change type to numpy array\n",
    "print(f'Pooled shape: {train_feature_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802dece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# This cell can take ~1-2 mins\n",
    "model = timm.create_model('resnet50', pretrained=True, num_classes=0) # download the model from timm\n",
    "testX_torch = torch.from_numpy(testX.swapaxes(1,3)) # turn testX into tensor and fix channel dimension\n",
    "test_feature_embeddings = model(testX_torch) # fit model to test images and get test feature embeddings\n",
    "test_feature_embeddings = test_feature_embeddings.detach().numpy() # change type to numpy array\n",
    "print(f'Pooled shape: {test_feature_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83792c57",
   "metadata": {},
   "source": [
    "## 4. Use cleanlab to find outliers in the dataset\n",
    "With just the feature embeddings, we can use the `cleanlab` library to try and find the artificially added outlier examples `[airplanes, automobiles, trucks, boats]` in the test dataset. We can also check the training data to find any naturally occuring outlier examples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aacc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleanlab\n",
    "from cleanlab.rank import get_outlier_scores\n",
    "from sklearn.neighbors import NearestNeighbors # import KNN estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49026d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KNN estimator and fit it on the resnet50 feature embeddings\n",
    "knn = NearestNeighbors(n_neighbors=10).fit(train_feature_embeddings)\n",
    "\n",
    "# get outlier scores for the test feature embeddings\n",
    "outlier_scores = get_outlier_scores(features=test_feature_embeddings, knn=knn, k=10)\n",
    "\n",
    "# visualize top 15 outlier scores\n",
    "top_outlier_idxs = (outlier_scores).argsort()[:15]\n",
    "plot_images(testX[top_outlier_idxs],testy[top_outlier_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25a681",
   "metadata": {},
   "source": [
    "Notice how majority of the outliers belong to the holdout classes (airplane, automobile, ship). These feature representations are futher away in the model representation space than the training dataset representations. \n",
    "\n",
    "Just for fun, lets visualize what the NearestNeighbors algorithm considers the 15 least probable outliers in our test set. Notice there are a lot less images from the out of distribution classes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fd623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize least probable 15 outlier scores\n",
    "bottom_outlier_idxs = (-outlier_scores).argsort()[:15]\n",
    "plot_images(testX[bottom_outlier_idxs],testy[bottom_outlier_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf08aa3",
   "metadata": {},
   "source": [
    "We can also compute the precision/recall of our algorithm for the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c9df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "animal_labels = [2,3,4,5,6,7] # identify animal labels in the testing dataset\n",
    "animal_idxs = np.where(np.isin(testy, animal_labels))[0] # find idx of animals\n",
    "not_outlier = np.zeros(len(testy), dtype=bool) # is outlier\n",
    "not_outlier[animal_idxs] = True\n",
    "precision, recall, thresholds = precision_recall_curve(not_outlier, 1 - outlier_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\", fontsize=14)\n",
    "plt.ylabel(\"Precision\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692f978",
   "metadata": {},
   "source": [
    "### Finding naturally occuring outlier examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76571ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outlier scores for our train feature embeddings\n",
    "outlier_scores = get_outlier_scores(features=train_feature_embeddings, k=10)\n",
    "\n",
    "# visualize top 15 outlier scores\n",
    "top_train_outlier_idxs = (outlier_scores).argsort()[:15]\n",
    "plot_images(trainX[top_train_outlier_idxs],trainy[top_train_outlier_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d203a",
   "metadata": {},
   "source": [
    "Just for fun, lets see what our model considers the least likeley outliers in the training set! These examples are very homogeneous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize bottom 12 outlier scores on train set\n",
    "top_outlier_idxs = (-outlier_scores).argsort()[:15]\n",
    "plot_images(trainX[top_outlier_idxs],trainy[top_outlier_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c554498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This cell is only for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "top_outlier_idxs_test = [ 1280, 13254,  6725, 13708, 11397, 11276,  4115,  6938, 14509, 9438,  9832,  3589, 12862,  8287,  4846]\n",
    "bottom_outlier_idxs_test =[6165, 5020, 8466, 4322, 1914, 5113, 6697, 7608,  273, 7802, 7795,4325, 6125,  910, 8448]\n",
    "\n",
    "if not all(x in top_outlier_idxs for x in top_outlier_idxs_test):\n",
    "    raise Exception(\"Some highlighted examples are missing from top outliers in test set.\")\n",
    "\n",
    "if not all(x in bottom_outlier_idxs for x in bottom_outlier_idxs_test):\n",
    "    raise Exception(\"Some highlighted examples are missing from bottom test set outliers.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanlab-p38",
   "language": "python",
   "name": "cleanlab-p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
