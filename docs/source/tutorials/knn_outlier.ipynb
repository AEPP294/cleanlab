{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f65acd",
   "metadata": {},
   "source": [
    "# Detecting Outliers with Cleanlab and PyTorch Image Models (timm)\n",
    "\n",
    "This 5-minute quickstart tutorial shows how to detect potential outliers in image classification data using Cleanlab and PyTorch. The dataset used is `cifar10` which contains 60,000 images. Each image belongs to 1 of 10 categories: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. \n",
    "\n",
    "**Overview of what we'll do in this tutorial:**\n",
    "\n",
    "- Load the [cifar10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset and do some basic data pre-processing.\n",
    "- Create `trainset` and `testset` such that `testset` contains extra categories\n",
    "- Load pretrained model and extract feature embeddings of `trainset` and `testset`\n",
    "- Compute outlier scores for each example using cleanlab's `get_outlier_scores` method and analyze results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e987fa",
   "metadata": {},
   "source": [
    "## 1. Install the required dependencies\n",
    "You can use `pip` to install all packages required for this tutorial as follows:\n",
    "\n",
    "```ipython3\n",
    "!pip install torch\n",
    "!pip install cleanlab\n",
    "...\n",
    "# Make sure to install the version corresponding to this tutorial\n",
    "# E.g. if viewing master branch documentation:\n",
    "#     !pip install git+https://github.com/cleanlab/cleanlab.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b552a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package installation (hidden on docs website).\n",
    "# If running on Colab, may want to use GPU (select: Runtime > Change runtime type > Hardware accelerator > GPU)\n",
    "# Package versions we used: matplotlib==3.5.1, numpy==1.21.6, torch==1.11.0, scikit-learn==1.0.2, torchvision==0.12.0, timm==0.5.4, cleanlab==2.0.0\n",
    "\n",
    "dependencies = ['builtins','torch','torchvision','torchvision.transforms','numpy','matplotlib.pyplot','warnings','cleanlab','timm']\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):  # Check if it's running in Google Colab\n",
    "    %pip install cleanlab  # for colab\n",
    "    cmd = ' '.join([dep for dep in dependencies if dep != \"cleanlab\"])\n",
    "    %pip install $cmd\n",
    "else:\n",
    "    missing_dependencies = []\n",
    "    for dependency in dependencies:\n",
    "        try:\n",
    "            __import__(dependency)\n",
    "        except ImportError:\n",
    "            missing_dependencies.append(dependency)\n",
    "\n",
    "    if len(missing_dependencies) > 0:\n",
    "        print(\"Missing required dependencies:\")\n",
    "        print(*missing_dependencies, sep=\", \")\n",
    "        print(\"\\nPlease install them before running the rest of this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e76f30",
   "metadata": {},
   "source": [
    "Lets first import the required packages and set some seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4de93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "import warnings\n",
    "\n",
    "import cleanlab\n",
    "from cleanlab.rank import get_outlier_scores\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.neighbors import NearestNeighbors # import KNN estimator\n",
    "import timm # resnet50 pre-trained model\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "warnings.filterwarnings(\"ignore\", \"Lazy modules are a new feature.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d0618",
   "metadata": {},
   "source": [
    "## 2. Fetch and scale the Cifar10 dataset\n",
    "\n",
    "Import `cifar10` dataset. After some basic preprocessing, we manually remove some categories from the training examples thereby making them outliers in the test set. For this example we've chosen to remove all categories that are not an animal `[airplane, automobile, ship, truck]` from the training set `trainX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783460c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select how to load the cifar10 datasets. Load into tensors for training.\n",
    "transform_normalize = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# Load cifar10 datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_normalize)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_normalize)\n",
    "\n",
    "# Manually remove non-animals out of the training dataset\n",
    "animal_labels = [2,3,4,5,6,7]\n",
    "trainy = trainset.targets # get labels\n",
    "animal_idxs = np.where(np.isin(trainy, animal_labels))[0] # find idx of animals\n",
    "trainset  = torch.utils.data.Subset(trainset, animal_idxs) # select only animals for the train set\n",
    "\n",
    "# Check the shapes of our training and test sets\n",
    "print('Trainset length: %s' % (len(trainset)))\n",
    "print('Testset length: %s' % (len(testset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4480c85",
   "metadata": {},
   "source": [
    "#### Lets visualize some of the training and test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b9be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_labels = {0: 'airplane', \n",
    "              1: 'automobile', \n",
    "              2: 'bird',\n",
    "              3: 'cat', \n",
    "              4: 'deer', \n",
    "              5: 'dog', \n",
    "              6: 'frog', \n",
    "              7: 'horse', \n",
    "              8:'ship', \n",
    "              9:'truck'}\n",
    "\n",
    "def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    return np.transpose(npimg, (1, 2, 0))\n",
    "\n",
    "def plot_images(dataset):\n",
    "    plt.rcParams[\"figure.figsize\"] = (9,7)\n",
    "    for i in range(15):\n",
    "        X,y = dataset[i]\n",
    "        ax = plt.subplot(3,5,i+1)\n",
    "        ax.set_title(txt_labels[int(y)])\n",
    "        ax.imshow(imshow(X))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dddf313",
   "metadata": {},
   "source": [
    "Observe how there are only animals left in the training set `trainset` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486acf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf11eb8",
   "metadata": {},
   "source": [
    "The test set on the other hand still visibily contains the non-animal images: `[ship, airplane, automobile, truck]`. If we consider `trainset` to be the representative of the normal data distribution then these non-animal images in test dataset `testset` become outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2fdd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f57bae",
   "metadata": {},
   "source": [
    "## 3. Import a model and get embeddings\n",
    "The model we are importing comes from [timm](https://timm.fast.ai/), a deep-learning library collection of SOTA models and utilities. \n",
    "\n",
    "We pass in the images into the model to generate embeddings in the feature space that we require as inputs for the outlier detection algorithm. The model in this tutorial is a `resnet50` but outlier detection can be done with any method capable of generating feature embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37785b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model from timm\n",
    "model = timm.create_model('resnet50', pretrained=True, num_classes=0)\n",
    "model.eval()\n",
    "\n",
    "# Create dataloaders for more efficient data streaming to the model\n",
    "batch_size = 50\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cef040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell can take ~1-2 mins\n",
    "train_feature_embeddings = []\n",
    "\n",
    "for data in trainloader:\n",
    "    images, labels = data\n",
    "    with torch.no_grad():\n",
    "        feature_embeddings = model(images) # Generate feature embeddings of the training data using the model\n",
    "        train_feature_embeddings.extend(feature_embeddings.numpy())\n",
    "train_feature_embeddings = np.array(train_feature_embeddings)\n",
    "\n",
    "print(f'Train embeddings pooled shape: {train_feature_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe10df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell can take ~1-2 mins\n",
    "test_feature_embeddings = []\n",
    "\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    with torch.no_grad():\n",
    "        feature_embeddings = model(images) # Generate feature embeddings of the test data using the model\n",
    "        test_feature_embeddings.extend(feature_embeddings.numpy())\n",
    "test_feature_embeddings = np.array(test_feature_embeddings)\n",
    "print(f'Test embeddings pooled shape: {test_feature_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83792c57",
   "metadata": {},
   "source": [
    "## 4. Use cleanlab to find outliers in the dataset\n",
    "With just the feature embeddings, we can use the `cleanlab` library to try and find the artificially added outlier examples `[airplanes, automobiles, trucks, boats]` in the test dataset. We can also check the training examples to find any naturally occuring outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49026d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KNN estimator and fit it on the train feature embeddings\n",
    "knn = NearestNeighbors(n_neighbors=20).fit(train_feature_embeddings)\n",
    "\n",
    "# Get outlier scores for the test feature embeddings\n",
    "outlier_scores = get_outlier_scores(features=test_feature_embeddings, knn=knn)\n",
    "\n",
    "# Visualize top 15 outlier scores\n",
    "top_outlier_idxs = (outlier_scores).argsort()[:15]\n",
    "top_outlier_subset = torch.utils.data.Subset(testset, top_outlier_idxs)\n",
    "plot_images(top_outlier_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25a681",
   "metadata": {},
   "source": [
    "Notice how a lot of the outliers in `testset` belong to the holdout classes `[airplane, automobile, ship]`. These feature representations are futher away in the model representation space than the feature representations of animal images also found in `trainset`. The other outlier examples are the stranger, more out of distribution pictures of animals.\n",
    "\n",
    "Just for fun, lets visualize what the `NearestNeighbors` algorithm considers the 15 least probable outliers in our test set. Notice there are a lot less images from the out of distribution classes here and all the images are visually similar to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fd623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize least probable 15 outlier scores\n",
    "bottom_outlier_idxs = (-outlier_scores).argsort()[:15]\n",
    "bottom_outlier_subset = torch.utils.data.Subset(testset, bottom_outlier_idxs)\n",
    "plot_images(bottom_outlier_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf08aa3",
   "metadata": {},
   "source": [
    "We can also compute the precision/recall curve of our algorithm for the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c9df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_labels = [2,3,4,5,6,7] # identify animal labels in the testing dataset\n",
    "animal_idxs = np.where(np.isin(testset.targets, animal_labels))[0] # find idx of animals\n",
    "not_outlier = np.zeros(len(testset.targets), dtype=bool)\n",
    "not_outlier[animal_idxs] = True\n",
    "precision, recall, thresholds = precision_recall_curve(not_outlier, 1 - outlier_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\", fontsize=14)\n",
    "plt.ylabel(\"Precision\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692f978",
   "metadata": {},
   "source": [
    "### Finding naturally occuring outlier examples\n",
    "\n",
    "We can also use ``get_outlier_scores()`` to find outlier examples in our training dataset. These examples should be animal images that are strange or different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76571ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outlier scores for our train feature embeddings\n",
    "outlier_scores = get_outlier_scores(features=train_feature_embeddings)\n",
    "\n",
    "# visualize top 15 outlier scores\n",
    "top_train_outlier_idxs = (outlier_scores).argsort()[:15]\n",
    "top_train_outlier_subset = torch.utils.data.Subset(trainset, top_train_outlier_idxs)\n",
    "plot_images(top_train_outlier_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d203a",
   "metadata": {},
   "source": [
    "Just for fun, lets see what our model considers the least likeley outliers in the training set! These examples should be very homogeneous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize bottom 15 outlier scores on train set\n",
    "bottom_train_outlier_idxs = (-outlier_scores).argsort()[:15]\n",
    "bottom_train_outlier_subset = torch.utils.data.Subset(trainset, bottom_train_outlier_idxs)\n",
    "plot_images(bottom_train_outlier_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c554498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This cell is only for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "top_outlier_idxs_test = [9834, 3820, 2381, 4810, 3291, 6352, 7488, 7368, 4587, 9965, 6927, 2719, 9831, 2130, 9175]\n",
    "top_outlier_idxs_train = [26999, 20198,  7967, 29061, 16684,  2558, 23072,   454,  5815, 9967, 27499, 22507,  8488, 20685,  9880]\n",
    "\n",
    "if not all(x in top_outlier_idxs for x in top_outlier_idxs_test):\n",
    "    raise Exception(\"Some highlighted examples are missing from top outliers in test set.\")\n",
    "\n",
    "if not all(x in top_train_outlier_idxs for x in top_outlier_idxs_train):\n",
    "    raise Exception(\"Some highlighted examples are missing from bottom test set outliers.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanlab-p38",
   "language": "python",
   "name": "cleanlab-p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
