{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1043b220",
   "metadata": {},
   "source": [
    "# Detecting Outlier Examples with Cleanlab and PyTorch Image Models (timm)\n",
    "\n",
    "This 5-minute tutorial shows how to detect outliers examples in image data using Cleanlab and PyTorch. We use the **cifar10** dataset where each image belongs to 1 of 10 classes: `[airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck]`. You can easily replace the image dataset + neural network used here with any other Pytorch dataset + neural network (e.g. to instead detect outliers in text data). \n",
    "\n",
    "**Overview of what we'll do in this tutorial:**\n",
    "\n",
    "Detecting outliers using `feature_embeddings`\n",
    "- Pre-process [cifar10](https://www.cs.toronto.edu/~kriz/cifar.html) to create a Pytorch dataset.\n",
    "- Create `train_data` and `test_data` such that `train_data` only contains images of animals and `test_data` contains images from all classes.\n",
    "- Load pretrained `timm` neural network model and extract `train_data` and `test_data` feature embeddings from its representations.\n",
    "- Use `cleanlab` to find naturally occurring outlier examples in the `train_data` (i.e. atypical images).\n",
    "- Find outlier examples in the `test_data` that do not stem from training data distribution (including out-of-distribution non-animal images).\n",
    "- Explore threshold selection for determining which images are outliers vs not.\n",
    "\n",
    "Detecting outliers using `pred_probs`\n",
    "- Train Logistic Regression classifier on the feature embeddings generated by `timm` model.\n",
    "- Use `cleanlab` to find naturally occuring OOD examples in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70016f64",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Quickstart\n",
    "<br/>\n",
    "    \n",
    "Already have numeric **feature embeddings** for your data? Just run the code below to compute out-of-distribution feature scores.\n",
    "\n",
    "\n",
    "<div  class=markdown markdown=\"1\" style=\"background:white;margin:16px\">  \n",
    "    \n",
    "```python\n",
    "\n",
    "from cleanlab.outlier import OutOfDistribution\n",
    "    \n",
    "OOD = OutOfDistribution()\n",
    "\n",
    "# To get outlier scores for train_data using feature matrix train_feature_embeddings\n",
    "ood_train_feature_scores = OOD.fit_score(features=train_feature_embeddings)\n",
    "\n",
    "# To get outlier scores for additional test_data using feature matrix test_feature_embeddings\n",
    "ood_test_feature_scores = OOD.score(features=test_feature_embeddings)\n",
    "    \n",
    "    \n",
    "```\n",
    "\n",
    "</div>\n",
    "    \n",
    "Already have `pred_probs` and `labels` for your data? Just run the code below to compute out-of-distribution predictions scores.\n",
    "\n",
    "\n",
    "<div  class=markdown markdown=\"1\" style=\"background:white;margin:16px\">  \n",
    "    \n",
    "```python\n",
    "\n",
    "from cleanlab.outlier import OutOfDistribution\n",
    "    \n",
    "OOD = OutOfDistribution()\n",
    "\n",
    "# To get outlier scores for train_data using train prediction probabilities and example labels\n",
    "ood_train_predictions_scores = OOD.fit_score(pred_probs=train_pred_probs, labels=labels)\n",
    "\n",
    "# To get outlier scores for additional test_data using test prediction probabilities\n",
    "ood_test_predictions_scores = OOD.score(pred_probs=test_pred_probs)\n",
    "    \n",
    "    \n",
    "```\n",
    "    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cb0f90",
   "metadata": {},
   "source": [
    "## 1. Install the required dependencies\n",
    "You can use `pip` to install all packages required for this tutorial as follows:\n",
    "\n",
    "```ipython3\n",
    "!pip install matplotlib sklearn torch torchvision timm\n",
    "!pip install cleanlab\n",
    "...\n",
    "# Make sure to install the version corresponding to this tutorial\n",
    "# E.g. if viewing master branch documentation:\n",
    "#     !pip install git+https://github.com/cleanlab/cleanlab.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbebfc8",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Package installation (hidden on docs website).\n",
    "# If running on Colab, may want to use GPU (select: Runtime > Change runtime type > Hardware accelerator > GPU)\n",
    "# Package versions we used: matplotlib==3.5.1, torch==1.11.0, torchvision==0.12.0, timm==0.5.4\n",
    "\n",
    "dependencies = [\"matplotlib\", \"torch\", \"torchvision\", \"sklearn\", \"timm\", \"cleanlab\"]\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):  # Check if it's running in Google Colab\n",
    "    %pip install cleanlab  # for colab\n",
    "    cmd = ' '.join([dep for dep in dependencies if dep != \"cleanlab\"])\n",
    "    %pip install $cmd\n",
    "else:\n",
    "    missing_dependencies = []\n",
    "    for dependency in dependencies:\n",
    "        try:\n",
    "            __import__(dependency)\n",
    "        except ImportError:\n",
    "            missing_dependencies.append(dependency)\n",
    "\n",
    "    if len(missing_dependencies) > 0:\n",
    "        print(\"Missing required dependencies:\")\n",
    "        print(*missing_dependencies, sep=\", \")\n",
    "        print(\"\\nPlease install them before running the rest of this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41733949",
   "metadata": {},
   "source": [
    "Let's first import the required packages and set some seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4396f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "import warnings\n",
    "\n",
    "import cleanlab\n",
    "from cleanlab.outlier import OutOfDistribution\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.neighbors import NearestNeighbors # import KNN estimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import timm # resnet50 pre-trained model\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "warnings.filterwarnings(\"ignore\", \"Lazy modules are a new feature.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be38283d",
   "metadata": {},
   "source": [
    "## 2. Pre-process the Cifar10 dataset\n",
    "\n",
    "After loading the data and processing the images, we manually remove some classes from the training dataset thereby making images from these classes outliers in the test set. For this example we've chosen to remove all classes that are not an animal, such that images from the following classes are considered out-of-distribution: `[airplane, automobile, ship, truck]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd853a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cifar10 images into tensors for training (rescales pixel values to [0,1] interval):\n",
    "transform_normalize = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),])\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_normalize)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_normalize)\n",
    "\n",
    "# Remove non-animal images from the training dataset\n",
    "animal_classes = [2,3,4,5,6,7]  # which labels correspond to images of animals\n",
    "animal_idxs = np.where(np.isin(train_data.targets, animal_classes))[0]\n",
    "\n",
    "# Only work with small subset of each dataset to speedup tutorial\n",
    "train_idxs = np.random.choice(animal_idxs, len(animal_idxs) // 6, replace=False)\n",
    "test_idxs = np.random.choice(range(len(test_data)), len(test_data) // 10, replace=False)\n",
    "\n",
    "train_data  = torch.utils.data.Subset(train_data, train_idxs)  # select subset of animal images for train_data\n",
    "test_data  = torch.utils.data.Subset(test_data, test_idxs)  # select subset of all images for test_data\n",
    "print('train_data length: %s' % (len(train_data)))\n",
    "print('test_data length: %s' % (len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be5ff2e",
   "metadata": {},
   "source": [
    "#### Visualize some of the training and test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_classes = {0: 'airplane', \n",
    "              1: 'automobile', \n",
    "              2: 'bird',\n",
    "              3: 'cat', \n",
    "              4: 'deer', \n",
    "              5: 'dog', \n",
    "              6: 'frog', \n",
    "              7: 'horse', \n",
    "              8:'ship', \n",
    "              9:'truck'}\n",
    "\n",
    "def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    return np.transpose(npimg, (1, 2, 0))\n",
    "\n",
    "def plot_images(dataset):\n",
    "    plt.rcParams[\"figure.figsize\"] = (9,7)\n",
    "    for i in range(15):\n",
    "        X,y = dataset[i]\n",
    "        ax = plt.subplot(3,5,i+1)\n",
    "        ax.set_title(txt_classes[int(y)])\n",
    "        ax.imshow(imshow(X))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb28f354",
   "metadata": {},
   "source": [
    "Observe how there are only animals left in the training set `train_data` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00aa3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df819e85",
   "metadata": {},
   "source": [
    "The test set on the other hand still visibily contains the non-animal images from classes like `[ship, airplane, automobile, truck]`. If we consider `train_data` to be representative of the typical data distribution, then these non-animal images in `test_data` become outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92caec8a",
   "metadata": {},
   "source": [
    "## 3. Represent each image as feature embeddings\n",
    "\n",
    "We construct a neural network and pass images through the network to generate vector embeddings via its hidden layer representation. Here we import a `resnet50` network from [timm](https://timm.fast.ai/), where this model has been pretrained on a large corpus of other images. \n",
    "\n",
    "Note that cleanlab's outlier detection can be applied to feature embeddings generated from any model (or to the raw data features if they are already numeric vectors). Outlier detection works best with moderately-dimensional feature vectors, in which values along each dimension are of a similar scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf25354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate 2048-dimensional feature embeddings from images\n",
    "def embed_images(model, dataloader):\n",
    "    feature_embeddings = []\n",
    "\n",
    "    for data in dataloader:\n",
    "        images, labels = data\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(images)\n",
    "            feature_embeddings.extend(embeddings.numpy())\n",
    "    feature_embeddings = np.array(feature_embeddings)\n",
    "    return feature_embeddings  # each row corresponds to embedding of a different image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a58d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download neural network from timm\n",
    "model = timm.create_model('resnet50', pretrained=True, num_classes=0)  # this is a pytorch network\n",
    "model.eval()  # eval mode disables training-time operators (like batch normalization)\n",
    "\n",
    "# Create dataloaders efficiently streaming images through the network\n",
    "batch_size = 50\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Generate feature embeddings of the training data using the model\n",
    "train_feature_embeddings = embed_images(model, trainloader)\n",
    "print(f'Train embeddings pooled shape: {train_feature_embeddings.shape}')\n",
    "\n",
    "# Generate feature embeddings of the test data using the model\n",
    "test_feature_embeddings = embed_images(model, testloader)\n",
    "print(f'Test embeddings pooled shape: {test_feature_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad857d69",
   "metadata": {},
   "source": [
    "## 4. Use cleanlab and `feature_embeddings` to find outliers in the dataset\n",
    "\n",
    "#### Scoring outliers in training data\n",
    "\n",
    "Fitting cleanlab's ``OutOfDistribution`` class on ``train_feature_embeddings`` will find any naturally occuring outliers in ``train_data``. These examples are atypical images that look strange or different from the majority of examples in the dataset. In our case, these correspond to odd-looking images of animals that do not resemble typical animals depicted in **cifar10**. This method produces a score in [0,1] for each example, where lower values correspond to more atypical examples (more likely out-of-distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OutOfDistribution object\n",
    "OOD = OutOfDistribution()\n",
    "\n",
    "# Fit and get out-of-distribution features scores for each of our train_data feature embeddings\n",
    "train_ood_features_scores = OOD.fit_score(features=train_feature_embeddings)\n",
    "\n",
    "# View images with top 15 out-of-distribution features scores\n",
    "top_train_ood_features_idxs = train_ood_features_scores.argsort()[:15]\n",
    "top_train_ood_features_scores_subset = torch.utils.data.Subset(train_data, top_train_ood_features_idxs)\n",
    "plot_images(top_train_ood_features_scores_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756333f7",
   "metadata": {},
   "source": [
    "For fun, let's see what `cleanlab` considers the least likely outliers in the training data! These examples look very homogeneous as each one is highly similar to many other training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 15 least likely outliers in train_data\n",
    "bottom_train_ood_features_idxs = (-train_ood_features_scores).argsort()[:15]\n",
    "bottom_train_ood_features_subset = torch.utils.data.Subset(train_data, bottom_train_ood_features_idxs)\n",
    "plot_images(bottom_train_ood_features_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521aefb",
   "metadata": {},
   "source": [
    "#### Scoring outliers in additional test data\n",
    "\n",
    "Now suppose we want to find outlier images in some never before seen test data, in particular images unlikely to stem from the same distribution as the training data. We can again use our fitted `OutOfDistribution` object to measure similarity between these new testing examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d039e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ood_features_scores = OOD.score(features=test_feature_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 15 most severe outliers in test data\n",
    "top_ood_features_idxs = (test_ood_features_scores).argsort()[:15]\n",
    "top_ood_features_subset = torch.utils.data.Subset(test_data, top_ood_features_idxs)\n",
    "plot_images(top_ood_features_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c645c58",
   "metadata": {},
   "source": [
    "Notice how almost all outliers identified in `test_data` belong to (non-animal) classes not present in the training data. These non-animal images have very different feature embeddings than the animal only training images and our `OutOfDistribution` object is able to detect that.\n",
    "\n",
    "#### Evaluating out of distribution detection performance \n",
    "\n",
    "Since we have access to ground-truth labels here (which is not necessary for outlier detection with cleanlab), \n",
    "we can evaluate our outlier scores for out-of-distribution detection, in which the goal is to find test images whose label does not correspond to any of the classes in the training data. We plot the precision/recall achieved by our outlier scores for the test data (which is a mix of animal and non-animal images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276acfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_labels = np.array(test_data.dataset.targets) # Get subset labels from out test_data\n",
    "animal_idxs = np.where(np.isin(test_data_labels[test_data.indices], animal_classes))[0] # Find animal idxs\n",
    "not_outlier = np.zeros(len(test_data), dtype=bool)\n",
    "not_outlier[animal_idxs] = True\n",
    "precision, recall, thresholds = precision_recall_curve(not_outlier, test_ood_features_scores)\n",
    "\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\", fontsize=14)\n",
    "plt.ylabel(\"Precision\", fontsize=14)\n",
    "plt.title(\"Out-of-Distribution Detection Performance\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5de6f6",
   "metadata": {},
   "source": [
    "#### Deciding which test examples are outliers\n",
    "\n",
    "Given outlier scores, how do we determine how many of the top-ranked examples in ``test_data`` should be marked as outliers? \n",
    "\n",
    "Inevitably this has some true positive / false positive trade-off, so let's suppose we want to ensure around at most 5% false positives. We can use the 5-th percentile of the distribution of `train_ood_features_scores` (assuming the training data are in-distribution examples without outliers) as a hard score threshold below which to consider a test example an outlier.\n",
    "\n",
    "Let's compute the 5th percentile of the training outlier score distribution (shown as red line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dff81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_percentile = np.percentile(train_ood_features_scores, 5)  # 5th percentile of the train_data distribution\n",
    "\n",
    "# Plot outlier_score distributions and the 5th percentile cutoff\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "plt_range = [min(train_ood_features_scores.min(),test_ood_features_scores.min()), \\\n",
    "             max(train_ood_features_scores.max(),test_ood_features_scores.max())]\n",
    "axes[0].hist(train_ood_features_scores, range=plt_range, bins=50)\n",
    "axes[0].set(title='train_outlier_scores distribution', ylabel='Frequency')\n",
    "axes[0].axvline(x=fifth_percentile, color='red', linewidth=2)\n",
    "axes[1].hist(test_ood_features_scores, range=plt_range, bins=50)\n",
    "axes[1].set(title='test_outlier_scores distribution', ylabel='Frequency')\n",
    "axes[1].axvline(x=fifth_percentile, color='red', linewidth=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c39ab1",
   "metadata": {},
   "source": [
    "All test examples whose `test_ood_features_scores` fall left of the red line will be marked as an outlier.\n",
    "\n",
    "Let's plot the least-certain outliers of our `test_data`. These are the images immediately to the left of that cutoff threshold (red line). The majority of them are still truly out-of-distribution non-animal images, but there are a few atypical-looking animals that are now erroneously identified as outliers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616769f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 15 images with outlier scores right along the cuttoff (i.e. those images we've identified as outliers that we're least sure about)\n",
    "sorted_idxs = test_ood_features_scores.argsort()\n",
    "ood_features_scores = test_ood_features_scores[sorted_idxs]\n",
    "ood_features_indices = sorted_idxs[ood_features_scores < fifth_percentile]  # Images in test data flagged as outliers\n",
    "\n",
    "selected_outlier_subset = torch.utils.data.Subset(test_data, ood_features_indices[::-1])\n",
    "plot_images(selected_outlier_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a044f1",
   "metadata": {},
   "source": [
    "#### How does cleanlab detect outliers from feature values?\n",
    "\n",
    "Outlier scores are defined relative to the average distance (computed over feature values) between each example and its K nearest neighbors in the training data. Such scores have been found to be particularly effective for out-of-distribution detection, see this paper for more details:\n",
    "\n",
    "[Back to the Basics: Revisiting Out-of-Distribution Detection Baselines](https://arxiv.org/abs/2207.03061)\n",
    "\n",
    "\n",
    "Internally, `cleanlab` uses the `sklearn.neighbors.NearestNeighbor` class (with *cosine* distance) to find the K nearest neighbors, but you can easily use another KNN estimator with `get_outlier_scores()`. Note that this class by default utilizes the *minkowski* distance, but we recommend using *cosine* distance between neural net representations of data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937c7e97",
   "metadata": {},
   "source": [
    "## 5. Use cleanlab and `pred_probs` to find outliers in the dataset\n",
    "\n",
    "\n",
    "Another way we can detect unusual exampels in the data is using prediction probabilities for out-of-distribution detection. Instead of using intermediate feature representations, this type of outlier detection simply needs a model's `pred_probs` to work. These methods are faster than using `feature_embeddings` but as a tradeoff perform slightly worse. This is due to the intermediate feature embeddings containing more auxillary information for every example, only some of which is represented in the final predicted probabilites.\n",
    "\n",
    "To get `pred_probs` for this example, a Logistic Regression Classifier is fit on the already generated `train_feature_embeddings` from the outlier example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fed4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "train_labels = np.array(train_data.dataset.targets)[train_data.indices]\n",
    "train_labels = np.unique(train_labels, return_inverse=True)[1] # Zero index out train labels\n",
    "test_labels = np.array(test_data.dataset.targets)[test_data.indices]\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train_feature_embeddings)\n",
    "train_feature_embeddings_scaled = scaler.transform(train_feature_embeddings)\n",
    "test_feature_embeddings_scaled = scaler.transform(test_feature_embeddings)\n",
    "\n",
    "# Create model and fit on scaled features and zero indexed train labels (may take a few minutes)\n",
    "model = LogisticRegression(penalty='l2', C=1, solver='sag', max_iter=500)\n",
    "model.fit(train_feature_embeddings_scaled, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e3f7b7",
   "metadata": {},
   "source": [
    "Lets see how well our model fit by checking its accuracy on the train examples. We can also compute out-of-distribution predictions scores for the train dataset using cleanlab's `OutOfDistribution` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e110fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model predictions and measure accuracy on trainset\n",
    "train_pred_probs = model.predict_proba(train_feature_embeddings_scaled)\n",
    "pred_labels = train_pred_probs.argmax(1)\n",
    "accuracy = np.mean(pred_labels == train_labels)\n",
    "print(f\"Model fit to train_feature_embeddings accuracy on train_data {accuracy}\")\n",
    "\n",
    "# Compute outlier scores for train data\n",
    "OOD = OutOfDistribution()\n",
    "train_ood_predictions_scores = OOD.fit(pred_probs=train_pred_probs, labels=train_labels)\n",
    "\n",
    "## Visualize top 15 most severe outliers in train data if desired\n",
    "# top_idxs = (train_ood_predictions_scores).argsort()[:15]\n",
    "# top_subset = torch.utils.data.Subset(train_data, top_idxs)\n",
    "# plot_images(top_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb631419",
   "metadata": {},
   "source": [
    "Out-of-distribution predictions scores can also be computed on the test data by first calculating `pred_probs` using `test_feature_embeddings`. To do this, an `OutOfDistribution` object fitted on `train_pred_probs` can be used to score `test_pred_probs`.\n",
    "\n",
    "Visualizing the top 15 outliers of the test set we once again see many examples that are not animals. Many outliers were identified correctly! Since it was working with less information, using `pred_probs` for OOD detection performed worse than uing `feature_embeddings` as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f90d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model predictions on test set\n",
    "pred_probs = model.predict_proba(test_feature_embeddings_scaled)\n",
    "pred_labels = pred_probs.argmax(1)\n",
    "\n",
    "# Compute outlier scores for test data with confident_thresholds passed in\n",
    "test_ood_predictions_scores = OOD.score(pred_probs=pred_probs)\n",
    "\n",
    "# Visualize top 15 most severe outliers in test data\n",
    "top_ood_predictions_idxs = (test_ood_predictions_scores).argsort()[:15]\n",
    "top_ood_predictions_subset = torch.utils.data.Subset(test_data, top_ood_predictions_idxs)\n",
    "plot_images(top_ood_predictions_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f96fa6",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Note: This cell is only for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "# Verify the top identified test outliers data are mostly non-animal images\n",
    "num_animals = len([i for i in range(len(top_ood_features_subset)) if top_ood_features_subset[i][1] in animal_classes])\n",
    "if 1 - (num_animals / len(top_ood_features_subset)) < 0.81:\n",
    "    raise Exception(\"Not enough non-animal images amongst top-ranked outliers in test_data.\")\n",
    "    \n",
    "num_animals = len([i for i in range(len(top_ood_predictions_subset)) if top_ood_predictions_subset[i][1] in animal_classes])\n",
    "if 1 - (num_animals / len(top_ood_predictions_subset)) < 0.51:\n",
    "    raise Exception(\"Not enough non-animal images amongst top-ranked ood datapoints in test_data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
