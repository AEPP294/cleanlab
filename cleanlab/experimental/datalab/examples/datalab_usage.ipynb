{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datalab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 14:34:34.994446: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-30 14:34:34.994483: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'IssueManager' from partially initialized module 'cleanlab.experimental.datalab.issue_manager' (most likely due to a circular import) (/workspaces/cleanlab/cleanlab/experimental/datalab/issue_manager/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/cleanlab/cleanlab/experimental/datalab/examples/datalab_usage.ipynb Cell 3\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c5562756e74752d32302e30345c686f6d655c656c6961735c70726f6a656374735c636c65616e6c6162/workspaces/cleanlab/cleanlab/experimental/datalab/examples/datalab_usage.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_val_predict\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c5562756e74752d32302e30345c686f6d655c656c6961735c70726f6a656374735c636c65616e6c6162/workspaces/cleanlab/cleanlab/experimental/datalab/examples/datalab_usage.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mneighbors\u001b[39;00m \u001b[39mimport\u001b[39;00m NearestNeighbors\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c5562756e74752d32302e30345c686f6d655c656c6961735c70726f6a656374735c636c65616e6c6162/workspaces/cleanlab/cleanlab/experimental/datalab/examples/datalab_usage.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcleanlab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatalab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexamples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_generation\u001b[39;00m \u001b[39mimport\u001b[39;00m create_data, plot_data\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c5562756e74752d32302e30345c686f6d655c656c6961735c70726f6a656374735c636c65616e6c6162/workspaces/cleanlab/cleanlab/experimental/datalab/examples/datalab_usage.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcleanlab\u001b[39;00m \u001b[39mimport\u001b[39;00m Datalab\n",
      "File \u001b[0;32m/workspaces/cleanlab/cleanlab/__init__.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m token_classification\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m multilabel_classification\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatalab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatalab\u001b[39;00m \u001b[39mimport\u001b[39;00m Datalab\n",
      "File \u001b[0;32m/workspaces/cleanlab/cleanlab/experimental/datalab/datalab.py:32\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcleanlab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatalab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_issues\u001b[39;00m \u001b[39mimport\u001b[39;00m DataIssues\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcleanlab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatalab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m _Displayer\n\u001b[0;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcleanlab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatalab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfactory\u001b[39;00m \u001b[39mimport\u001b[39;00m _IssueManagerFactory\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcleanlab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatalab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mserialize\u001b[39;00m \u001b[39mimport\u001b[39;00m _Serializer\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m TYPE_CHECKING:  \u001b[39m# pragma: no cover\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/cleanlab/cleanlab/experimental/datalab/factory.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m annotations\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Dict, List, Type\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcleanlab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatalab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39missue_manager\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     IssueManager,\n\u001b[1;32m      7\u001b[0m     LabelIssueManager,\n\u001b[1;32m      8\u001b[0m     NearDuplicateIssueManager,\n\u001b[1;32m      9\u001b[0m     OutOfDistributionIssueManager,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     13\u001b[0m REGISTRY: Dict[\u001b[39mstr\u001b[39m, Type[IssueManager]] \u001b[39m=\u001b[39m {\n\u001b[1;32m     14\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutlier\u001b[39m\u001b[39m\"\u001b[39m: OutOfDistributionIssueManager,\n\u001b[1;32m     15\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m: LabelIssueManager,\n\u001b[1;32m     16\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnear_duplicate\u001b[39m\u001b[39m\"\u001b[39m: NearDuplicateIssueManager,\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     18\u001b[0m \u001b[39m# Construct concrete issue manager with a from_str method\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/cleanlab/cleanlab/experimental/datalab/issue_manager/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mduplicate\u001b[39;00m \u001b[39mimport\u001b[39;00m NearDuplicateIssueManager\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39missue_manager\u001b[39;00m \u001b[39mimport\u001b[39;00m IssueManager\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlabel\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelIssueManager\n",
      "File \u001b[0;32m/workspaces/cleanlab/cleanlab/experimental/datalab/issue_manager/duplicate.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mneighbors\u001b[39;00m \u001b[39mimport\u001b[39;00m NearestNeighbors\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m check_is_fitted\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcleanlab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatalab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39missue_manager\u001b[39;00m \u001b[39mimport\u001b[39;00m IssueManager\n\u001b[1;32m     12\u001b[0m \u001b[39mif\u001b[39;00m TYPE_CHECKING:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcleanlab\u001b[39;00m \u001b[39mimport\u001b[39;00m Datalab\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'IssueManager' from partially initialized module 'cleanlab.experimental.datalab.issue_manager' (most likely due to a circular import) (/workspaces/cleanlab/cleanlab/experimental/datalab/issue_manager/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from cleanlab.experimental.datalab.examples.data_generation import create_data, plot_data\n",
    "from cleanlab import Datalab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "We'll use a toy-dataset that puts the sum of two floats into one of three bins. The dataset, including the ground-truth labels, is created with the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = create_data()\n",
    "\n",
    "X_train, noisy_labels, y_train_idx, noisy_labels_idx, X_out = (\n",
    "    data_dict[key]\n",
    "    for key in [\n",
    "        \"X_train\", \"noisy_labels\", \"y_train_idx\", \"noisy_labels_idx\", \"X_out\"\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X_train, y_train_idx, noisy_labels_idx, X_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap data in a Dataset object\n",
    "data = Dataset.from_dict({\"X\": X_train, \"y\": noisy_labels})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get out-of-sample predicted probabilities from a classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "pred_probs = cross_val_predict(\n",
    "    estimator=model, X=data[\"X\"], y=data[\"y\"], cv=5, method=\"predict_proba\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate a Datalab object\n",
    "\n",
    "Provide the data object and a name of the label column in the data object.\n",
    "\n",
    "Most issue types currently rely on getting (out-of-sample) predictions from a trained model.\n",
    "We'll use a simple logistic regression model for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = Datalab(data, label_name=\"y\")\n",
    "lab.find_issues(pred_probs=pred_probs, features=\"X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can review some of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or view the issues directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary\")\n",
    "display(lab.issue_summary)\n",
    "\n",
    "print(\"Issues\")\n",
    "display(lab.issues)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental issue search\n",
    "\n",
    "We can call `find_issues` multiple times on a Datalab object to find issues incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = Datalab(data, label_name=\"y\")\n",
    "lab.find_issues(pred_probs=pred_probs, issue_types={\"outlier\": {}})\n",
    "lab.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the next check\n",
    "lab.find_issues(pred_probs=pred_probs, issue_types={\"label\": {}})\n",
    "lab.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous checks can be overwritten\n",
    "lab.find_issues(pred_probs=pred_probs, features=\"X\", issue_types={\"outlier\": {}})\n",
    "lab.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.issue_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing hyperparameter in issue search\n",
    "\n",
    "In this example, we'll use custom hyperparameters for the `\"outlier\"` and `\"near_duplicate\"` issue types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = Datalab(data, label_name=\"y\")\n",
    "knn = NearestNeighbors(n_neighbors=3, metric=\"euclidean\")\n",
    "issue_types = {\n",
    "    \"outlier\": {\"ood_kwargs\": {\"params\": {\"knn\": knn}}},\n",
    "    \"near_duplicate\": {\"metric\": \"euclidean\"},\n",
    "}\n",
    "\n",
    "lab.find_issues(\n",
    "    pred_probs=pred_probs,\n",
    "    features=\"X\",\n",
    "    issue_types=issue_types,\n",
    ")\n",
    "lab.report(k=10, verbosity=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how last 5 examples correspond to the synthetic outliers we added to the data, which includes the two points that had a lower cosine distance in the previous outlier-issue checks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a custom IssueManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab.experimental.datalab.issue_manager import IssueManager\n",
    "from cleanlab.experimental.datalab.factory import register as register_issue_manager\n",
    "\n",
    "\n",
    "def scoring_function(idx: int) -> float:\n",
    "    if idx == 0:\n",
    "        # Zero excluded from the divisibility check, gets the highest score\n",
    "        return 1\n",
    "    rem = idx % 13\n",
    "    inv_scale = idx // 13\n",
    "    if rem == 0:\n",
    "        return 0.5 * (1 - np.exp(-0.1*(inv_scale-1)))\n",
    "    else:\n",
    "        return 1 - 0.49 * (1 - np.exp(-inv_scale**0.5))*rem/13\n",
    "\n",
    "\n",
    "@register_issue_manager\n",
    "class SuperstitionIssueManager(IssueManager):\n",
    "    \"\"\"A custom issue manager that keeps track of issue indices that\n",
    "    are divisible by 13.\n",
    "    \"\"\"\n",
    "    issue_name: str = \"superstition\"\n",
    "\n",
    "    def find_issues(self, div=13, **_) -> None:\n",
    "        ids = self.datalab.issues.index.to_series()\n",
    "        issues_mask = ids.apply(lambda idx: idx % div == 0 and idx != 0)\n",
    "        scores = ids.apply(scoring_function)\n",
    "        self.issues = pd.DataFrame(\n",
    "            {\n",
    "                f\"is_{self.issue_name}_issue\": issues_mask,\n",
    "                self.issue_score_key: scores,\n",
    "            },\n",
    "        )\n",
    "        summary_score = 1 - sum(issues_mask) / len(issues_mask)\n",
    "        self.summary = self.get_summary(score = summary_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.find_issues(issue_types={\"superstition\": {}})\n",
    "lab.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"test-lab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Datalab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_lab = Datalab.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lab.info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
